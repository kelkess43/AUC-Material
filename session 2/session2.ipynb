{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47a8670",
   "metadata": {},
   "source": [
    "# Credit Scoring Dataset – First Look\n",
    "In this session, you will:\n",
    "- Explore a raw dataset for credit scoring.\n",
    "- Identify and fix common data quality issues.\n",
    "- Engineer new features useful for predicting credit risk.\n",
    "\n",
    "The dataset mimics real-world bank data, with deliberate issues (missing values, outliers, duplicates).\n",
    "\n",
    "> **Note for Students**  \n",
    "> This dataset is **synthetic** and created for **academic purposes only**.  \n",
    "> It is not real customer data, but it mimics some of the real issues (like missing values, inconsistent categories, and outliers) that we often face in actual credit scoring use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff5b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05996f7",
   "metadata": {},
   "source": [
    "# Section 1: Quick EDA (Exploratory Data Analysis)\n",
    "Before cleaning and feature engineering, let's understand the dataset.\n",
    "\n",
    "Goals:\n",
    "- Check dataset shape and column types\n",
    "- Inspect distributions of numeric variables\n",
    "- Explore categorical variables\n",
    "- Identify issues: missing values, outliers, inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8076f792",
   "metadata": {},
   "source": [
    "### Step 1.1 – Dataset Overview\n",
    "- Check shape and column types\n",
    "- Preview first rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30c12ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Read the CSV file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Preview the first 10 rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066a4d8",
   "metadata": {},
   "source": [
    "### Step 1.2 – Summary Statistics\n",
    "- Describe numeric variables\n",
    "- Count categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288caa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check data types and non-null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d01245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check value counts for 'employment_type'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e07667",
   "metadata": {},
   "source": [
    "### Step 1.3 – Missing Values\n",
    "- Identify columns with NaN\n",
    "- Check proportions of missing\n",
    "\n",
    "\n",
    "*Explanation*: Missing values can bias results. Small amounts may be dropped, but important fields are often imputed with logical strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aafdb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find missing values in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3db16",
   "metadata": {},
   "source": [
    "### Step 1.4 – Distributions & Outliers\n",
    "- Plot histograms for numeric columns\n",
    "- Use boxplots to detect outliers\n",
    "\n",
    "\n",
    "*Explanation*: Visualizing distributions helps detect skewness, outliers, or unrealistic values (e.g., negative income)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=\"age\", nbins=30, title=\"Age Distribution\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a histogram to visualize income distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558060c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.histogram(df, x=\"monthly_balance\", nbins=30, title=\"Monthly Balance Distribution\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a243ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a boxplot to check for outliers in monthly_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492dfd06",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "- Income shows wide variation, with some higher earners but many around lower ranges.\n",
    "- Monthly balance has outliers — some customers go very negative or very high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6523559d",
   "metadata": {},
   "source": [
    "### Step 1.5 – Target Variable\n",
    "- Check distribution of the target\n",
    "- See if classes are balanced (default vs non-default)\n",
    "\n",
    "*Explanation*: Checking class balance is critical. If imbalanced, advanced techniques like resampling or weighted models may be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddc497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Print raw counts of default vs non-default instead of percentages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribution of default vs non-default\n",
    "default_dist = df['default'].value_counts(normalize=True).reset_index()\n",
    "default_dist.columns = ['default', 'proportion']\n",
    "\n",
    "fig = px.bar(\n",
    "    default_dist,\n",
    "    x='default',\n",
    "    y='proportion',\n",
    "    text='proportion',\n",
    "    title=\"Default vs Non-default Distribution\",\n",
    "    labels={'default': 'Class', 'proportion': 'Proportion'}\n",
    ")\n",
    "fig.update_traces(texttemplate='%{text:.2%}', textposition='outside')\n",
    "fig.update_yaxes(tickformat=\".0%\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29079027",
   "metadata": {},
   "source": [
    "### Class Imbalance Note\n",
    "\n",
    "In this dataset, about 20% of customers are **defaults** while 80% are **non-defaults**. This reflects a realistic imbalance: most customers repay their loans. However, this imbalance means accuracy alone is misleading — we need to also look at precision, recall, and F1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7596a2d",
   "metadata": {},
   "source": [
    "# Section 2: Data Cleaning\n",
    "Now we fix issues found in EDA.\n",
    "\n",
    "Goals:\n",
    "- Handle missing values, duplicates, and outliers.\n",
    "- Standardize categories and check data consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a1e37",
   "metadata": {},
   "source": [
    "### Step 2.1 – Handle Missing Values\n",
    "Choose a strategy:\n",
    "- Drop rows\n",
    "- Fill with mean/median/mode\n",
    "- Use domain knowledge (e.g., employment type → \"Unknown\")\n",
    "\n",
    "\n",
    "*Explanation*: Imputation choice depends on distribution. Median is safer with skewed data (like income), while mean works for symmetric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e63b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill missing values for 'age' and 'employment_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f274e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income'] = df['income'].fillna(df['income'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cb81b0",
   "metadata": {},
   "source": [
    "### Step 2.2 – Remove Duplicates\n",
    "- Check duplicate rows\n",
    "- Drop if necessary\n",
    "\n",
    "*Explanation*: Duplicates usually arise from repeated entries. Always confirm before dropping, since some repeats may be legitimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Remove duplicate rows from the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa799e2e",
   "metadata": {},
   "source": [
    "### Step 2.3 – Standardize Categories\n",
    "- Fix inconsistent labels\n",
    "- Ensure uniform formatting (e.g., lowercase)\n",
    "\n",
    "\n",
    "*Explanation*: Standardizing categories avoids treating 'Self employed' and 'self-employed' as separate groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Standardize categories in 'employment_type'\n",
    "# Hint: lowercase and strip spaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc258ad",
   "metadata": {},
   "source": [
    "### Step 2.4 – Treat Outliers\n",
    "- Cap extreme values\n",
    "- Or replace with thresholds\n",
    "\n",
    "*Explanation*: Outliers can heavily influence models. Options include capping, transformation (log), or removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b53bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solved example: cap outliers at 99th percentile\n",
    "cap = df['monthly_balance'].quantile(0.99)\n",
    "df['monthly_balance'] = np.where(df['monthly_balance'] > cap, cap, df['monthly_balance'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede885bc",
   "metadata": {},
   "source": [
    "### Step 2.5 – Validate Logic\n",
    "- Check impossible values (e.g., negative age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = np.where(df['age'] < 0, abs(df['age']), df['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ffc469",
   "metadata": {},
   "source": [
    "# Section 3: Feature Engineering\n",
    "We create new features that add business insight.\n",
    "\n",
    "Goals:\n",
    "- Encode categorical variables.\n",
    "- Build useful ratios (e.g., debt-to-income, credit utilization).\n",
    "- Group variables (e.g., age buckets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb255114",
   "metadata": {},
   "source": [
    "### Step 3.1 – Encode Categorical Variables\n",
    "- Convert categories into numeric form (e.g., one-hot encoding)\n",
    "- Avoid implying order in non-ordinal categories\n",
    "\n",
    "*Explanation*: Encoding turns categories into numeric form. One-hot encoding avoids implying order in non-ordinal categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b40714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solved example: encode 'education'\n",
    "df = pd.get_dummies(df, columns=['education'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Encode other categorical variables like 'employment_type' and 'gender'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d3b53",
   "metadata": {},
   "source": [
    "### Step 3.2 – Create Ratios\n",
    "- Debt-to-Income Ratio\n",
    "- Credit Utilization (%)\n",
    "\n",
    "*Explanation*: Ratios like debt-to-income capture relative financial health better than raw numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c80d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solved example: Debt-to-Income ratio\n",
    "df['debt_to_income'] = df['total_debt'] / (df['income']+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create credit utilization (balance / credit_limit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e02c3",
   "metadata": {},
   "source": [
    "### Step 3.3 – Group Continuous Variables\n",
    "- Age buckets\n",
    "- Income ranges\n",
    "\n",
    "*Explanation*: Bucketing continuous variables can reveal non-linear relationships (e.g., young borrowers may behave differently).  \n",
    "It also makes it easier to compare customers across categories (e.g., low-income vs high-income).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_group'] = pd.cut(df['age'], bins=[18,30,50,100], labels=['Young','Mid','Senior'])\n",
    "\n",
    "# TODO: Create alternative age groups with different splits\n",
    "\n",
    "# TODO: Create income ranges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa2b27",
   "metadata": {},
   "source": [
    "## 🔍 Feature Insights After Engineering\n",
    "\n",
    "Now that we created **debt-to-income ratio, credit utilization, age groups, and income groups**, we can visualize how these engineered features relate to default risk.\n",
    "\n",
    "The goal is to see whether these transformations reveal clearer patterns compared to the raw features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe393d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solved example: Debt-to-Income vs Default\n",
    "fig1 = px.box(\n",
    "    df,\n",
    "    x='default',\n",
    "    y='debt_to_income',\n",
    "    title='Debt-to-Income Ratio vs Default',\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "# TODO: Plot Credit Utilization vs Default\n",
    "# Hint: Use px.box with 'default' on x-axis and 'credit_utilization' on y-axis\n",
    "\n",
    "# Solved example: Default rate by Income Group\n",
    "income_group_default = df.groupby('income_group')['default'].mean().reset_index()\n",
    "fig3 = px.bar(\n",
    "    income_group_default,\n",
    "    x='income_group',\n",
    "    y='default',\n",
    "    title='Default Rate by Income Group'\n",
    ")\n",
    "fig3.show()\n",
    "\n",
    "# TODO: Plot Default rate by Age Group\n",
    "# Hint: Group by 'age_group' and calculate mean default rate, then use px.bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db9870c",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "- Customers with high **debt-to-income ratios** are clearly riskier.\n",
    "- **Credit utilization** close to 1.0 (maxing out their credit limit) signals much higher default probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00449a",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "- Lower income groups show a much higher proportion of defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933d507",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- Customers with **higher debt-to-income ratios** are more likely to default.\n",
    "- **Credit utilization above 0.8** signals higher default risk.\n",
    "- Lower income groups have visibly higher default rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2a6de",
   "metadata": {},
   "source": [
    "## Section 4: Simple Modelling\n",
    "\n",
    "Now that the dataset is cleaned and features engineered, we can try a simple model.\n",
    "- Split data into train/test sets\n",
    "- Fit a Logistic Regression model\n",
    "- Evaluate using accuracy, precision, recall, and F1-score\n",
    "\n",
    "⚠️ Note: The goal is not to achieve the best model here, but to connect the data preparation steps with prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5303dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define target and features\n",
    "y = df['default']\n",
    "X = df.drop(columns=['default','customer_id'])\n",
    "\n",
    "# One-hot encode categorical variables if any remain\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Default','Default'], yticklabels=['Non-Default','Default'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
